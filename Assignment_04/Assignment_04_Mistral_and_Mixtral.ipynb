{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "mount_file_id": "1uhRI4NKcTooAscc3M2hjB8Amr0xX1w4D",
      "authorship_tag": "ABX9TyNUj3J6oqA3AAxkpnx/zpxI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18b367f01a5f474c8e2235d4468111b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b3aacff2dcf4fb595ea75a2666a303c",
              "IPY_MODEL_2a2fc36bea3c4e5dabc5c39bee43c8b5",
              "IPY_MODEL_dcf5b27b7a8a49239f090af76dc14999"
            ],
            "layout": "IPY_MODEL_5bc5a96c98b6450ea1d84dbd4e796d9d"
          }
        },
        "0b3aacff2dcf4fb595ea75a2666a303c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb9f5b7c8094916873226e9761d3eea",
            "placeholder": "​",
            "style": "IPY_MODEL_b75e2ef8abd84382b7c595b05b3eba1d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2a2fc36bea3c4e5dabc5c39bee43c8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ea9f7836e84583b15d0aac25cdcc61",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c579ec77b98d4082aae197a8e6c3fa3b",
            "value": 2
          }
        },
        "dcf5b27b7a8a49239f090af76dc14999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_260cdcbe382f4cdfba27e625729eb6b8",
            "placeholder": "​",
            "style": "IPY_MODEL_a4b2f25482c34a8a81d89b8f86c9a7f7",
            "value": " 2/2 [00:05&lt;00:00,  2.49s/it]"
          }
        },
        "5bc5a96c98b6450ea1d84dbd4e796d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb9f5b7c8094916873226e9761d3eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b75e2ef8abd84382b7c595b05b3eba1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05ea9f7836e84583b15d0aac25cdcc61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c579ec77b98d4082aae197a8e6c3fa3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "260cdcbe382f4cdfba27e625729eb6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b2f25482c34a8a81d89b8f86c9a7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamcnguyen89/CAP_6411_Assignments/blob/main/Assignment_04/Assignment_04_Mistral_and_Mixtral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 4: Mistral vs Mixtral Pipeline**\n",
        "\n",
        "\n",
        "\n",
        "*   Got to https://people.eecs.berkeley.edu/~hendrycks/data.tar\n",
        "*   Colab should have both mixtral and mistral 7b pipelines\n",
        "*   Compare both in terms of speed and accuracy\n",
        "*   Bonus: 100 points for applying SMoE to other models\n",
        "*   Due 03Sep2024\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "epk6kUuPcsSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mistral-7b** \\\n",
        "Mistral-7B is one of the biggest and most advanced Large Language Models out there, trained on a massive dataset of text and code.\n",
        "\n",
        "Link: https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/13\n",
        "\n",
        "**Mixtral 8x7b** \\\n",
        "Mixtral 8x7b is a high-quality sparse mixture of experts (SMoE) model with open weights created by Mistral AI. It outperforms Llama 2 70B on most benchmarks and batches or beats GPT3.5 on most standard benchmarks.\n",
        "\n",
        "Link: https://github.com/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb\n"
      ],
      "metadata": {
        "id": "zyAXeeKeeUg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Mistral-7B Model and Test**"
      ],
      "metadata": {
        "id": "T7N6ZBZ1O0-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Mistral-7B Model\n",
        "!pip -q install git+https://github.com/huggingface/transformers # need to install from github\n",
        "!pip -q install bitsandbytes accelerate xformers einops\n",
        "!pip -q install langchain\n",
        "!pip install --upgrade huggingface_hub\n",
        "\n",
        "# You need to go onto Google Colab and create a variable in Secrets. This variable will contain a token for the huggingface account that we will get our pretrained models from\n",
        "from google.colab import userdata\n",
        "secret = userdata.get('HF_TOKEN')\n",
        "!huggingface-cli login --token {secret}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ziBzTp2LlEL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1538a6-3084-4d52-fc6e-71a0cb4f4775"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.7.4)\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQzj8hQgt9y-",
        "outputId": "e96c1966-c775-4ac4-9bbd-50fecee5e216"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  2 23:53:23 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0              50W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "torch.set_default_device('cuda')"
      ],
      "metadata": {
        "id": "EFbxeDluATgg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Pretrained model and load into memory\n",
        "# Note I required a GPU with 40gb of memory for this project.\n",
        "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "                                             torch_dtype=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "                                          torch_dtype=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "18b367f01a5f474c8e2235d4468111b2",
            "0b3aacff2dcf4fb595ea75a2666a303c",
            "2a2fc36bea3c4e5dabc5c39bee43c8b5",
            "dcf5b27b7a8a49239f090af76dc14999",
            "5bc5a96c98b6450ea1d84dbd4e796d9d",
            "6fb9f5b7c8094916873226e9761d3eea",
            "b75e2ef8abd84382b7c595b05b3eba1d",
            "05ea9f7836e84583b15d0aac25cdcc61",
            "c579ec77b98d4082aae197a8e6c3fa3b",
            "260cdcbe382f4cdfba27e625729eb6b8",
            "a4b2f25482c34a8a81d89b8f86c9a7f7"
          ]
        },
        "id": "w3qIw7EdAcTM",
        "outputId": "eaa89fe9-276e-4423-ad85-0c6ebe4c0793"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18b367f01a5f474c8e2235d4468111b2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to Prompt Mistral AI Models: https://community.aws/content/2dFNOnLVQRhyrOrMsloofnW0ckZ/how-to-prompt-mistral-ai-models-and-why\n",
        "\n",
        "\n",
        "text = \"<s>[INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> [INST] Do you have mayonnaise recipes? [/INST]\"\n",
        "\n",
        "encodeds = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
        "\n",
        "device = 'cuda'\n",
        "model_inputs = encodeds.to(device)\n",
        "model.to(device)\n",
        "\n",
        "generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rI344zEDcWA",
        "outputId": "64571cb2-d432-4e5c-d5fd-0b64a2e4d0a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> [INST] Do you have mayonnaise recipes? [/INST] Certainly! Here's a simple recipe for homemade mayonnaise that you can try out:\n",
            "\n",
            "Ingredients:\n",
            "\n",
            "* 1 cup mayonnaise\n",
            "* 1 egg yolk\n",
            "* 1 tablespoon Dijon mustard\n",
            "* 1 garlic clove, minced\n",
            "* 1/4 cup champagne vinegar or white wine vinegar\n",
            "* 1/2 teaspoon salt\n",
            "* 1/4 teaspoon black pepper\n",
            "* 3 tablespoons vegetable oil\n",
            "\n",
            "Instructions:\n",
            "\n",
            "1. In a medium-sized mixing bowl, whisk together the egg yolk, dijon mustard, minced garlic, and vinegar until well combined.\n",
            "2. Slowly whisk in the vegetable oil, continue whisking until the mixture thickens and is a pale yellow in color.\n",
            "3. Season with salt and pepper to taste.\n",
            "4. Cover the bowl with plastic wrap and refrigerate for at least an hour before using.\n",
            "\n",
            "Note: It's best to use fresh ingredients for the best taste.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and Process Dataset**\n"
      ],
      "metadata": {
        "id": "HFijHlS9Oi48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://github.com/mddunlap924/PyTorch-LLM/blob/main/notebooks/training.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "xI1VJNl0OeUg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}